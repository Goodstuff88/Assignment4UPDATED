---
title: "Assignment 4"
author: "Gustav Oosthuizen - OSTGUS001"
date: '`r format(Sys.Date(), "%d-%B-%Y")`'
output:
  pdf_document:
    highlight: pygments
    keep_tex: yes
    number_sections: yes
    toc: yes
    toc_depth: 4
    fig_caption: true
citation_package: "biblatex"
bibliography: "Ass_4.bib"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\pagebreak

```{r installing packages, include=FALSE}

#Steps:

# 1. Installing "basic" packages:

#install.packages("tidyverse")
#install.packages("remotes")

library(tidyverse)
library(remotes)
library(plotly)

# 2. Installing packages used to get corona virus data set

#remotes::install_github('pzhaonet/ncovr')
#install.packages("ncovr")
#library(ncovr)

```

```{r Loadinging and transforming most current data, include=FALSE}

###### CODE DOES NOT WORK ######
# 
# # Note: Only run the following chunk if the latest conona data wants to be obtained:
# 
# # Run the following command to get the latest data
# ncov <- get_ncov()
# 
# # To only extract the "area" data frame
# ncov <- ncov$area
# 
# # a function for converting Julian time to ymd_
# conv_time <- function(x){
#   as.POSIXct('1970-01-01', tz = 'GMT') + x / 1000
# }
# 
# # convert updateTime from Julian date to ymd-hms
# ncov$updateTime <- conv_time(ncov$updateTime)
# 
# 
# # Will save the latest data 
# save(ncov, file = "ncov-latest.Rdata")

```

\section{Data wrangling} \label{DW section}

The data wrangling consist of importing, tidying and transforming the data set [@wickham2016r].

\subsection{Imporing data} 

As mentioned in section \ref{DW section} the first step of data wrangling is importing the data.
```{r importing data, echo=FALSE}

# Importing the data set "ncov"

load("C:/Users/Gustav/Desktop/MSc Data Science 1st year/Exploratory data analysis/Assignments/Assignment4/ncov-latest (1).Rdata")

head(ncov, 5)

```  

\subsection{Tiding and transforming the data}

The second and thrid steps of data wrangling is tiding and transforming the data. The variables of the "ncovr" data set will be investigated and the nesseccary changes/transformations will be made to get the data in a tidy format.   

```{r ncovr variable investigation, include=FALSE}

# Steps:

# 1. General structure of the data set:

glimpse(ncov)

structure(ncov)

# 2. Variables that seem to have no value and should be removed.

# provinceName: Chinese writings - no use
# provinceShortName: Chinese writings - no use
# comment: Chinese writings - no use
# statisticsData: Contains a lot of NA's. Cant see the use in variable that gives link.
# cities: Contains a lot of NULL values that are useless.
# countryName: Chinese writings - no use
# continentName:Chinese writings - no use
# operator: No use for assignment
# countryShortCode: Contains a lot of NA's. Would Rather remove.
# createTime: Contains a lot of NA's and dont know meaning
# modifyTime: Contains a lot of NA's and dont know meaning 
# cityName: Contains no names and NA's
# province_en: Contains no names and NA's 

#3.1 Investigating "comment" variable:

ncov %>%
  filter(comment != "") %>%
  count()

# Conclution: Most rows (7598) have no comments in them and it 

#3.2 investigating "location.ID" variable:

sum(is.na(ncov$locationId))

# Conclution: No missing values, can be useful.

#3.3 Investigating "statisticsData" variable:

sum(is.na(ncov$statisticsData))

ncov %>%
  filter(!is.na(ncov$statisticsData))

#Conclution:Contains a lot of NA values

#3.4 Investigating "cities" variable

# view first data frame in list

ncov$cities[1]

# Conclution: Contains a lot of NULL values. Values that are not NUll are data frames that seem to have similar but less data of than the original data set. 

#3.5 Investigating "operator" variable

sum(is.na(ncov$operator))

ncov %>%
  filter(!is.na(ncov$operator))
  
# Conclution: Don't see the use of including variable for the purpose of assignment.

#3.6 Investigating "countryShortCode" variable

sum(is.na(ncov$countryShortCode))

# Conclution: Contains a lot of NA's. Would Rather remove.

# 3.6 Investigating "province_en" variable 

sum(is.na(ncov[,23]))

ncov %>%
  filter(!is.na(province_en))

# Conclution: Contains a lot of NA's. Would Rather remove

```


```{r Removing unswanted variables from ncov, echo=FALSE}

ncov_Updated <- ncov %>%
  select(-c("provinceName", "provinceShortName", "comment", "statisticsData", "cities", "countryName", "continentName","operator", "countryShortCode", "createTime", "modifyTime", "cityName", "province_en" ))

head(ncov_Updated,5)
```



\section{Visualisations}

As seen by figure \ref{fig:Normal_Distribution}, the normal distribution is plotted.
Remember the default figure width height is 6 x 4.5 

```{r Normal_Distribution, fig.height= 3, fig.width=4.5 , fig.align='center', fig.cap= "The normal distribution curve", echo=FALSE}

x <- rnorm(100)

hist(x)


```

\pagebreak

\section{References}

